"""
Core LLM Functions - extracted from ai_backlinking_llm.py
"""
import os
from loguru import logger

# Remove static environment variable loading - will read dynamically
# SERPER_API_KEY = os.getenv("SERPER_API_KEY")
# FIRECRAWL_API_KEY = os.getenv("FIRECRAWL_API_KEY")
# OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
# GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

def _get_openai_api_key():
    """Get OPENAI_API_KEY dynamically from environment"""
    return os.getenv("OPENAI_API_KEY")

def _get_gemini_api_key():
    """Get GEMINI_API_KEY dynamically from environment"""
    return os.getenv("GEMINI_API_KEY")


def llm_text_gen(
    prompt: str,
    provider: str = "gemini",
    model: str | None = None,
    openai_api_key: str | None = None,
    gemini_api_key: str | None = None,
) -> str:
    """Generate text using selected provider (Gemini or OpenAI), with graceful fallback."""
    provider_normalized = (provider or "").strip().lower()
    if provider_normalized in ("gemini", "google", "google-gemini"):
        key = gemini_api_key or _get_gemini_api_key()
        if not key:
            return f"[AI Draft]\n{prompt.strip()}\n\n--\nThis is a placeholder draft (no Gemini API key)."
        try:
            import google.generativeai as genai  # type: ignore
            genai.configure(api_key=key)
            model_name = model or "gemini-2.5-flash"
            gmodel = genai.GenerativeModel(model_name)
            resp = gmodel.generate_content(prompt)
            text = getattr(resp, "text", None)
            return (text or "").strip() or f"[AI Draft]\n{prompt.strip()}\n\n--\nNo content returned."
        except Exception as exc:
            logger.warning(f"Gemini generation failed: {exc}")
            return f"[AI Draft]\n{prompt.strip()}\n\n--\nThis is a placeholder draft (Gemini error)."

    # Default to OpenAI
    key = openai_api_key or _get_openai_api_key()
    if not key:
        return f"[AI Draft]\n{prompt.strip()}\n\n--\nThis is a placeholder draft (no OpenAI API key)."
    try:
        from openai import OpenAI  # type: ignore
        client = OpenAI(api_key=key)
        model_name = model or "gpt-4o-mini"
        response = client.chat.completions.create(
            model=model_name,
            temperature=0.7,
            max_tokens=700,
            messages=[
                {"role": "system", "content": "You are a helpful outreach assistant who writes concise, friendly, highly personalized guest-post outreach emails."},
                {"role": "user", "content": prompt},
            ],
        )
        content = (response.choices[0].message.content or "").strip()
        return content or f"[AI Draft]\n{prompt.strip()}\n\n--\nNo content returned."
    except Exception as exc:
        logger.warning(f"OpenAI generation failed: {exc}")
        return f"[AI Draft]\n{prompt.strip()}\n\n--\nThis is a placeholder draft (OpenAI error)."


def compose_personalized_email(
    website_data,
    insights,
    user_proposal,
    provider: str = "gemini",
    model: str | None = None,
    openai_api_key: str | None = None,
    gemini_api_key: str | None = None,
):
    """
    Compose a personalized outreach email using AI LLM based on website data, insights, and user proposal.

    Args:
        website_data (dict): The data of the website including metadata and contact info.
        insights (str): Insights generated by the LLM about the website.
        user_proposal (dict): The user's proposal for a guest post or content contribution.

    Returns:
        str: A personalized email message.
    """
    contact_name = website_data.get("contact_info", {}).get("name", "Webmaster")
    # Prefer explicit metadata title, else domain as site name
    site_name = website_data.get("metadata", {}).get("title") or website_data.get("domain") or "your site"
    proposed_topic = user_proposal.get("topic", "a guest post")
    user_name = user_proposal.get("user_name", "Your Name")
    user_email = user_proposal.get("user_email", "your_email@example.com")

    email_prompt = f"""
You are an AI assistant tasked with composing a highly personalized outreach email for guest posting.

Contact Name: {contact_name}
Website Name: {site_name}
Proposed Topic: {proposed_topic}

User Details:
Name: {user_name}
Email: {user_email}

Website Insights: {insights}

Please compose a professional and engaging email that includes:
1. A personalized introduction addressing the recipient.
2. A mention of the website's content focus.
3. A proposal for a guest post.
4. A call to action to discuss the guest post opportunity.
5. A polite closing with user contact details.
"""

    return llm_text_gen(
        email_prompt,
        provider=provider,
        model=model,
        openai_api_key=openai_api_key,
        gemini_api_key=gemini_api_key,
    )
